{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import src.visualize as viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 1
   },
   "source": [
    "# Modeling with PCA\n",
    "\n",
    "In this notebook, we develop a model to (somewhat) classify different outcomes when a person is stopped by a seattle police officer. The majority of the code in this notebook is completed, but we will ask you to apply PCA at the end. \n",
    "\n",
    "In the cell below, we load in a dataset from `seattle.gov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 2
   },
   "outputs": [],
   "source": [
    "from src.load_data import load_data\n",
    "police_data = load_data()\n",
    "police_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 3
   },
   "source": [
    "The target for this dataset is `Stop Resolution`. \n",
    "\n",
    "In the cell below, we seperate our target from the predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 4
   },
   "outputs": [],
   "source": [
    "target = police_data['Stop Resolution']\n",
    "police_modeling = police_data.drop('Stop Resolution', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 5
   },
   "source": [
    "Great. The data in our target are currently strings. Let's take a look at the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 6
   },
   "outputs": [],
   "source": [
    "series = target.value_counts(normalize=True)\n",
    "series.plot(kind='bar', figsize=(15,4))\n",
    "plt.xticks(ticks=[0,1,2,3,4],\n",
    "           labels=series.index.str.replace(' ', '\\n'),\n",
    "          rotation=0, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 7
   },
   "source": [
    "We definitely have class imbalance with this dataset where `Field Contact` makes up roughly 40% of all observations, and the two classes `Referred for Prosecution` and `Citation/Infraction` combined make up less than 5%. \n",
    "\n",
    "Knowing this, let's encode our target column as discrete integers, and see how well we can predict them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 8
   },
   "outputs": [],
   "source": [
    "# Import label encoder from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_encoder = LabelEncoder()\n",
    "target_encoder.fit(target)\n",
    "target_encoded = target_encoder.transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 9
   },
   "source": [
    "Ok next, we have a bit of preprocessing to do. There are several categorical columns in this dataset. In the cell below, let's create a `column transformer` that will `OneHotEncode` the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 10
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a list of categorical feature names\n",
    "categoricals = ['Subject Age Group','Weapon Type', \n",
    "                'Officer Gender', 'Officer Race', \n",
    "                'Subject Perceived Race', 'Subject Perceived Gender',\n",
    "                'Precinct', 'Sector', 'Beat']\n",
    "\n",
    "# Initialize a OneHotEncoder\n",
    "# Will set handle_unknown to 'ignore' so\n",
    "# new categories in our testing data do not \n",
    "# throw an error. We will also set sparse to `False`\n",
    "# to prevent the encoder from returning a sparse matrix.\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Create a tuple with the encoder at the first index\n",
    "# and the list of categorical features at the second index\n",
    "encoder_step = (encoder, categoricals)\n",
    "\n",
    "# Pass the tuple into `make_column_transformer`\n",
    "# and set remainder to 'passthrough' to prevent\n",
    "# the features we did not OneHotEncode  \n",
    "# from being dropped.\n",
    "encoder = make_column_transformer(encoder_step, \n",
    "                                  remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 11
   },
   "source": [
    "Now, we will test our encoder to make sure everything is working correctly, and compare the shape of our original dataset with the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 12
   },
   "outputs": [],
   "source": [
    "print('New shape:     ', encoder.fit_transform(police_modeling).shape)\n",
    "print('Original shape:', police_modeling.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 13
   },
   "source": [
    "-----\n",
    "With OneHotEncoding we went from 16 to 216 columns! This is a rather naive strategy, and it would almost certainly be a good idea to inspect these categorical features to see if there are some ways to bring the number of features down. Much like with modeling, we can consider this a \"baseline\" for preprocessing, where we will see how good of a model we can build with the most naive preprocessing choices.\n",
    "\n",
    "------\n",
    "\n",
    "Let's create a train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 14
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(police_modeling, target_encoded, \n",
    "                                                   random_state=2021, test_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 15
   },
   "source": [
    "# Some Modeling Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 16
   },
   "source": [
    "Our data is processed and ready to go! \n",
    "\n",
    "To successfully demonstrate an instance of PCA improving model performance, we will add a final feature to our data that was generated via `clustering`, which is a data science technique you will be introduced to tomorrow! \n",
    "\n",
    "In the cell below, we import the cluster feature and append it to our training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 17
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.get_clusters import get_clusters\n",
    "\n",
    "train_clusters, test_clusters = get_clusters(encoder, X_train, y_train, X_test)\n",
    "\n",
    "X_train['cluster'] = train_clusters\n",
    "X_test['cluster'] = test_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 18
   },
   "source": [
    "For this problem, we will use `f1 score` for the `0` class as our metric of success. The `0` class represents instances in which a police stop resulted in an arrest. \n",
    "\n",
    "### Sklearn Scorer\n",
    "A **scorer** is a sklearn wrapper that shortens our code a little when we are evaluating a model. \n",
    "\n",
    "Normally, to evaluate a model using f1, our code would look something like this:\n",
    "```python\n",
    "train_preds = model.predict(X_train)\n",
    "f1_score = f1_score(y_train, train_preds)\n",
    "```\n",
    "\n",
    "With a scorer object, we are able to cut this down to a single line:\n",
    "```python\n",
    "train_preds = scorer(model, X_train, y_train)\n",
    "```\n",
    "\n",
    "In the cell below, we create a `f1 scorer` that returns the f1 score for the `0` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 19
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Create a function that returns the\n",
    "# f1 score for the 0 class\n",
    "def precision(true, preds):\n",
    "    score = f1_score(true, preds, average=None)[0]\n",
    "    return score\n",
    "\n",
    "# Pass the scoring function into make_scorer\n",
    "scorer = make_scorer(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 20
   },
   "source": [
    "**Modeling Harness**\n",
    "\n",
    "In the cell below, we import a class called `ModelHarness`. This class contains code to speed up the modeling and model evaluation process. The code for this class is not particularly important, and is mostly for the purpose of making this notebook more succint. \n",
    "\n",
    "If you would like to take a look at the code, you can find it [here](src/ModelHarness.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 21
   },
   "outputs": [],
   "source": [
    "# Import the modeling harness\n",
    "from src.ModelHarness import ModelHarness\n",
    "# Pass in our modeling splits and the scorer\n",
    "harness = ModelHarness(X_train, X_test, y_train, y_test, scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 22
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 23
   },
   "source": [
    "Let's create a baseline Logistic Regression model. \n",
    "\n",
    "In the cell below, we construct a pipeline called `baseline_pipe` that receives our `encoder` preprocessing object and a Logistic Regression model. \n",
    "\n",
    "We then run the model and output some metrics using the modeling harness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 24
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create pipeline\n",
    "baseline_pipe = make_pipeline(encoder, LogisticRegression(solver='liblinear'))\n",
    "# Run model\n",
    "harness.run(baseline_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 25
   },
   "source": [
    "Our model seems to be doing really well for classes `2` and `3`, which also happen to be the classes with the most observations. Perhaps resampling will help. \n",
    "\n",
    "In the cell below, we create a pipeline called `lr_smote_pipe` that has the following steps:\n",
    "1. OneHotEncode the categoricals using the `encoder` column transformer\n",
    "1. Upsample our minority class using `SMOTE`\n",
    "1. Fit a Logistic Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 26
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Create smote logistic regression pipeline\n",
    "lr_smote_pipe = make_pipeline(encoder, SMOTE(), LogisticRegression(solver='liblinear'))\n",
    "\n",
    "# Run the model\n",
    "harness.run(lr_smote_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 27
   },
   "source": [
    "That improved performance, though we're only having moderate success at seperating these categories. Let's see how some other models perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 28
   },
   "source": [
    "### Decision Tree\n",
    "\n",
    "In the cell below, we fit a Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 29
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_pipe = make_pipeline(encoder, \n",
    "                        DecisionTreeClassifier(max_depth=10))\n",
    "\n",
    "harness.run(dt_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 30
   },
   "source": [
    "That's our best score yet! Let's see if smote helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 31
   },
   "source": [
    "### Decision Tree with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 32
   },
   "outputs": [],
   "source": [
    "dt_smote_pipe = make_pipeline(encoder, SMOTE(),\n",
    "                        DecisionTreeClassifier(max_depth=10))\n",
    "\n",
    "harness.run(dt_smote_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 33
   },
   "source": [
    "It looks like Decision Tree's aren't vibing much with smote. \n",
    "\n",
    "Let's move on to an ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 34
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 35
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = make_pipeline(encoder,\n",
    "                        RandomForestClassifier(max_depth=10,n_estimators=300,\n",
    "                                              class_weight='balanced_subsample'))\n",
    "\n",
    "harness.run(rf_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 36
   },
   "source": [
    "Our decision tree model is outperforming Random Forest. Given that random forests are made of a bunch of decision trees, and smote made our decision tree model's performance worse, it's unlikely smote will improve the performance of our random forest model. But let's check, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 37
   },
   "outputs": [],
   "source": [
    "rf_smote_pipe = make_pipeline(encoder, SMOTE(),\n",
    "                        RandomForestClassifier(max_depth=10,n_estimators=300,\n",
    "                                              class_weight='balanced_subsample'))\n",
    "\n",
    "harness.run(rf_smote_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 38
   },
   "source": [
    "Unsurprisingly, worse. Ok, we will use our modeling harness's `.history` attribute to output a dataframe of all our modeling scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 39
   },
   "outputs": [],
   "source": [
    "harness.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 40
   },
   "source": [
    "# Applying PCA\n",
    "\n",
    "Let's see if we can use PCA to improve our scores. Because PCA uses the covariance of our features to reduce the dimensions, generally PCA tends to perform better for linear models. \n",
    "\n",
    "Let's see if we can use PCA to improve the metrics for our Logistic Regression model.\n",
    "\n",
    "\n",
    "To really break down the steps of using PCA, we will step away from pipelines for a hot second. \n",
    "\n",
    "To apply PCA we will need to do the following:\n",
    "1. Use the OneHotEncoder column transformer we creating above to transform our training and testing data.\n",
    "2. Initialize an Sklearn scaler and scale our training and testing data.\n",
    "3. Initialize an Sklearn PCA object and transform our training and testing data.\n",
    "    * Set `n_components` to `.95`.\n",
    "        * Side bar: If you set n_components to an integer, you will reduce your dataset to that number of components. If you set `n_components` to a *float* you will reduce your dataset to whatever number of components capture that amount of your data's variance. So when we set `n_components` to `.95` we are saying \"Reduce our data to the number of components that capture 95% of our data.\"\n",
    "     * Set `random_state` to 2021.\n",
    "\n",
    "In the cell below, import `PCA` and `StandardScaler` from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 41
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "index": 42
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 43
   },
   "source": [
    "In the cell below, complete steps 1-3 that are detailed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 44
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "index": 45
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "encoder.fit(X_train)\n",
    "X_train_encoded = encoder.transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_encoded)\n",
    "X_train_scaled = scaler.transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "pca = PCA(n_components=.95, random_state=2021)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca= pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 46
   },
   "source": [
    "Now finally, fit a Logistic Regression model to the pca transformed training data.\n",
    "   * Set `solver` to \"liblinear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 47
   },
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "pca_lr = LogisticRegression(solver='liblinear')\n",
    "pca_lr.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 48
   },
   "source": [
    "Now score the model using `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "index": 49
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.28361045130641327\n",
      "Testing: 0.25405921680993315\n"
     ]
    }
   ],
   "source": [
    "#==SOLUTION== \n",
    "print('Training:', scorer(pca_lr, X_train_pca, y_train))\n",
    "print('Testing:', scorer(pca_lr, X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 50
   },
   "source": [
    "If we look back at our logistic regression modeling above, when we applied smote the model's performance improved by quite a lot. Let's see if adding smote into this PCA model will improve performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 51
   },
   "source": [
    "In the cell below, construct a **pipeline** called `final_pipeline` with the following steps:\n",
    "1. The column transformer that was created above\n",
    "1. An sklearn standard scaler\n",
    "1. An imblearn smote resampler to upsample the minority classes\n",
    "1. A PCA object to reduce dimensionality and captures 95% of the data's variance.\n",
    "1. A logistic regression model with a liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 52
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "index": 53
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "final_pipeline = make_pipeline(encoder, StandardScaler(), SMOTE(), PCA(n_components=.95),\n",
    "                        LogisticRegression(solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 54
   },
   "outputs": [],
   "source": [
    "# Run this cell to evaluate your pipeline's performance\n",
    "harness.run(final_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 55
   },
   "source": [
    "## Bonus:\n",
    "> Not relevant to tomorrow's checkpoint, but fun!\n",
    "\n",
    "Another tool that can be used for Dimensionality Reduction is `Linear Discriminant Analysis` (LDA). This tool is very similar to PCA, but instead of finding components to explain the variance of the data, it finds components to maximize the seperation of the target classes. [Here](https://www.youtube.com/watch?v=azXCzI57Yfc) is a good statquest video that breaks down LDA.\n",
    "\n",
    "Below, we replace PCA with LDA to produce better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 56
   },
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(encoder, StandardScaler(), SMOTE(), \n",
    "                        LinearDiscriminantAnalysis(n_components=3),\n",
    "                        LogisticRegression(solver='liblinear'))\n",
    "\n",
    "harness.run(lr_pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
